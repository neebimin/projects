{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Suicide Watch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook 3: Model Selection and Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the codes to assess the effectiveness of potential classification models using the preprocessed data, including:\n",
    "\n",
    "* Multinomial Naive Bayes\n",
    "* K-Nearest Neighbors\n",
    "* Logistic Regression Classifier\n",
    "\n",
    "Models are tested using two vectorization transformers: CountVectorizer, TF-IDF\n",
    "\n",
    "A GridSearch is run across all models to rule out non-viable options. The models with the most predictive potential are then selected and optimised here:\n",
    "\n",
    "* Tfidf + Multinomial Naive Bayes\n",
    "* Tfidf + Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "\n",
    "- [Train/Test Split (Lemmatized Posts)](#Train/Test-Split-(Lemmatized-Posts))\n",
    "- [Grid Search CV](#Grid-Search-CV)\n",
    "    * [Baseline Accuracy](#Baseline-Accuracy)\n",
    "    * [Count Vectorizer](#Count-Vectorizer)\n",
    "    * [Tfidf Vectorizer](#Tfidf-Vectorizer)\n",
    "- [Train/Test Split (Stemmed Posts)](#Train/Test-Split-(Stemmed-Posts))\n",
    "- [Grid Search CV](#Grid-Search-CV)\n",
    "    * [Count Vectorizer](#Count-Vectorizer)\n",
    "    * [Tfidf Vectorizer](#Tfidf-Vectorizer)\n",
    "- [Optimising Tfidf Multinomial Naive Bayes](#Optimising-Tfidf-Multinomial-Naive_Bayes)\n",
    "- [Optimising Tfidf Logistic Regression](#Optimising-Tfidf-Logistic-Regression)\n",
    "- [Conclusion-and-Recommendations](#Conclusion-and-Recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "# preprocessing imports\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "\n",
    "# modeling imports\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# plotting imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split (Lemmatized Posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_lem</th>\n",
       "      <th>post_stem</th>\n",
       "      <th>suicide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ask  kindly  stop     make tea  read  text  p...</td>\n",
       "      <td>ask  kindli  stop     make tea  read  text  p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u ryfflex    still   please let  know   year ...</td>\n",
       "      <td>u ryfflex    still   pleas let  know   year a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>broken kid like mei see  many people  like ...</td>\n",
       "      <td>broken kid like mei see  mani peopl  like  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anyone angry  bitter   time    tolerate anybo...</td>\n",
       "      <td>anyon angri  bitter   time    toler anybodi  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>could use someone  talk</td>\n",
       "      <td>could use someon  talk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            post_lem  \\\n",
       "0   ask  kindly  stop     make tea  read  text  p...   \n",
       "1   u ryfflex    still   please let  know   year ...   \n",
       "2     broken kid like mei see  many people  like ...   \n",
       "3   anyone angry  bitter   time    tolerate anybo...   \n",
       "4                           could use someone  talk    \n",
       "\n",
       "                                           post_stem  suicide  \n",
       "0   ask  kindli  stop     make tea  read  text  p...        1  \n",
       "1   u ryfflex    still   pleas let  know   year a...        1  \n",
       "2     broken kid like mei see  mani peopl  like  ...        1  \n",
       "3   anyon angri  bitter   time    toler anybodi  ...        1  \n",
       "4                            could use someon  talk         1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import preprocessed data\n",
    "df_prep = pd.read_csv('../datasets/preprocessed.csv')\n",
    "df_prep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set feature, X and target, y variables for lemmatized posts for train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_prep['post_lem']\n",
    "y = df_prep['suicide']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since it is classification problem, we will stratify y to ensure equal split of X and y \n",
    "# in train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in X_train: 1417\n",
      "Number of rows in y_train: 1417\n",
      "Number of rows in X_test: 473\n",
      "Number of rows in y_test: 473\n"
     ]
    }
   ],
   "source": [
    "# Confirm that train and test variables have the same length\n",
    "print('Number of rows in X_train: {}'.format(len(X_train)))\n",
    "print('Number of rows in y_train: {}'.format(len(y_train)))\n",
    "print('Number of rows in X_test: {}'.format(len(X_test)))\n",
    "print('Number of rows in y_test: {}'.format(len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV\n",
    "\n",
    "The GridSearchCV tool allows us to program multiple hyperparameters across our models. It will generate a model with each combination of our desired hyperparameters, and optimize the highest-scoring result.\n",
    "\n",
    "We will run a model for each of the following classifiers:\n",
    "\n",
    "* Multinomial Naive Bayes\n",
    "* K-Nearest Neighbors\n",
    "* Logistic Regression\n",
    "\n",
    "We will run two GridSearches to benchmark these models for two feature extraction techniques: CountVectorizer and TfidfVectorizer. We can use the accuracy of the results to narrow our model selection to the most effective approaches.\n",
    "\n",
    "As these models execute, the results will be displayed, then stored into a DataFrame for final comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5172900494001411"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline accuracy\n",
    "baseline = y_train.value_counts(normalize=True)[1]\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we find the baseline accuracy, which is the likelihood of a post being from the suicide subreddit, by calculating the percentage of the dataset that is the target value of 1. Normalising the value counts shows the percentage, and gives a baseline accuracy of 51.7%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline steps for each combination of model\n",
    "# Include standard scaler for knn and logistic regression because distance are important when classifying\n",
    "steps_list_cv = [ \n",
    "    [('cv', CountVectorizer()),('multi_nb', MultinomialNB())],\n",
    "    [('cv', CountVectorizer()),('scaler', StandardScaler(with_mean=False)),('knn', KNeighborsClassifier())], \n",
    "    [('cv', CountVectorizer()),('scaler', StandardScaler(with_mean=False)),('logreg', LogisticRegression())]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_titles_cv = ['multi_nb + cv','knn + cv','logreg + cv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params_cv = [\n",
    "    {'cv__stop_words':['english'], 'cv__ngram_range':[(1,1),(1,2)]},\n",
    "    {'cv__stop_words':['english'], 'cv__ngram_range':[(1,1),(1,2)]},\n",
    "    {'cv__stop_words':['english'], 'cv__ngram_range':[(1,1),(1,2)]}\n",
    "]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>baseline_accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, best_params, train_accuracy, test_accuracy, baseline_accuracy, recall, precision, f1-score]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate results DataFrame for CountVectorizer\n",
    "gs_results_cv = pd.DataFrame(columns=['model','best_params','train_accuracy','test_accuracy',\n",
    "                                      'baseline_accuracy','recall', 'precision', 'f1-score'])\n",
    "gs_results_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  multi_nb + cv\n",
      "Best Params:  {'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}\n",
      "0.9174311926605505 \n",
      "\n",
      "0.693446088794926 \n",
      "\n",
      "True Negatives: 150\n",
      "False Positives: 78\n",
      "False Negatives: 67\n",
      "True Positives: 178 \n",
      "\n",
      "Model:  knn + cv\n",
      "Best Params:  {'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}\n",
      "0.5335215243472125 \n",
      "\n",
      "0.5179704016913319 \n",
      "\n",
      "True Negatives: 3\n",
      "False Positives: 225\n",
      "False Negatives: 3\n",
      "True Positives: 242 \n",
      "\n",
      "Model:  logreg + cv\n",
      "Best Params:  {'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}\n",
      "0.9992942836979535 \n",
      "\n",
      "0.6257928118393234 \n",
      "\n",
      "True Negatives: 126\n",
      "False Positives: 102\n",
      "False Negatives: 75\n",
      "True Positives: 170 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through index of number of steps\n",
    "for i in range(len(steps_list_cv)):\n",
    "    # instantiate pipeline \n",
    "    pipe = Pipeline(steps=steps_list_cv[i])\n",
    "    # fit GridSearchCV to model and model's params\n",
    "    gs = GridSearchCV(pipe, pipe_params_cv[i], cv=3) \n",
    "\n",
    "    model_results = {}\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    print('Model: ', steps_titles_cv[i])\n",
    "    model_results['model'] = steps_titles_cv[i]\n",
    "\n",
    "    print('Best Params: ', gs.best_params_)\n",
    "    model_results['best_params'] = gs.best_params_\n",
    "\n",
    "    print(gs.score(X_train, y_train), '\\n')\n",
    "    model_results['train_accuracy'] = gs.score(X_train, y_train)\n",
    "    \n",
    "    print(gs.score(X_test, y_test), '\\n')\n",
    "    model_results['test_accuracy'] = gs.score(X_test, y_test)\n",
    "    \n",
    "    model_results['baseline_accuracy'] = baseline\n",
    "    \n",
    "    # Display the confusion matrix results showing true/false positive/negative\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, gs.predict(X_test)).ravel() \n",
    "    print(\"True Negatives: %s\" % tn)\n",
    "    print(\"False Positives: %s\" % fp)\n",
    "    print(\"False Negatives: %s\" % fn)\n",
    "    print(\"True Positives: %s\" % tp, '\\n')\n",
    "    \n",
    "    model_results['recall'] = tp/(tp+fn)\n",
    "    model_results['precision'] = tp/(tp+fp)\n",
    "    model_results['f1-score'] = 2*((tp/(tp+fp))*(tp/(tp+fn)))/((tp/(tp+fp))+(tp/(tp+fn)))\n",
    "\n",
    "    gs_results_cv = gs_results_cv.append(model_results, ignore_index=True)\n",
    "    pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>baseline_accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multi_nb + cv</td>\n",
       "      <td>{'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}</td>\n",
       "      <td>0.917431</td>\n",
       "      <td>0.693446</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>0.726531</td>\n",
       "      <td>0.695312</td>\n",
       "      <td>0.710579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg + cv</td>\n",
       "      <td>{'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}</td>\n",
       "      <td>0.999294</td>\n",
       "      <td>0.625793</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.657640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn + cv</td>\n",
       "      <td>{'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}</td>\n",
       "      <td>0.533522</td>\n",
       "      <td>0.517970</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>0.987755</td>\n",
       "      <td>0.518201</td>\n",
       "      <td>0.679775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model                                               best_params  \\\n",
       "0  multi_nb + cv  {'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}   \n",
       "2    logreg + cv  {'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}   \n",
       "1       knn + cv  {'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}   \n",
       "\n",
       "   train_accuracy  test_accuracy  baseline_accuracy    recall  precision  \\\n",
       "0        0.917431       0.693446            0.51729  0.726531   0.695312   \n",
       "2        0.999294       0.625793            0.51729  0.693878   0.625000   \n",
       "1        0.533522       0.517970            0.51729  0.987755   0.518201   \n",
       "\n",
       "   f1-score  \n",
       "0  0.710579  \n",
       "2  0.657640  \n",
       "1  0.679775  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results_cv.sort_values('test_accuracy',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although Multinomial NB gave the highest test accuracy, there seems to be a high overfitting of training data since the training data accuracy is much higher than the testing data accuracy for both Multinomial NB and Logistic Regression. All three models have a higher accuracy than the baseline, but only barely so for KNearestNeighbours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_list_tf = [ \n",
    "    [('tf',TfidfVectorizer()),('multi_nb',MultinomialNB())],\n",
    "    [('tf',TfidfVectorizer()),('scaler',StandardScaler(with_mean=False)),('knn',KNeighborsClassifier())], \n",
    "    [('tf',TfidfVectorizer()),('scaler',StandardScaler(with_mean=False)),('logreg',LogisticRegression())]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_titles_tf = ['multi_nb + tf','knn + tf','logreg + tf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params_tf = [\n",
    "    {\"tf__stop_words\":['english'], \"tf__ngram_range\":[(1,1),(1,2)]},\n",
    "    {\"tf__stop_words\":['english'], \"tf__ngram_range\":[(1,1),(1,2)]},\n",
    "    {\"tf__stop_words\":['english'], \"tf__ngram_range\":[(1,1),(1,2)]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>baseline_accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, best_params, train_accuracy, test_accuracy, baseline_accuracy, recall, precision, f1-score]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate results DataFrame\n",
    "gs_results_tf = pd.DataFrame(columns=['model','best_params','train_accuracy','test_accuracy','baseline_accuracy',\n",
    "                                      'recall', 'precision', 'f1-score'])\n",
    "gs_results_tf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  multi_nb + tf\n",
      "Best Params:  {'tf__ngram_range': (1, 1), 'tf__stop_words': 'english'}\n",
      "0.9414255469301341 \n",
      "\n",
      "0.7145877378435518 \n",
      "\n",
      "True Negatives: 143\n",
      "False Positives: 85\n",
      "False Negatives: 50\n",
      "True Positives: 195 \n",
      "\n",
      "Model:  knn + tf\n",
      "Best Params:  {'tf__ngram_range': (1, 1), 'tf__stop_words': 'english'}\n",
      "0.5172900494001411 \n",
      "\n",
      "0.5179704016913319 \n",
      "\n",
      "True Negatives: 0\n",
      "False Positives: 228\n",
      "False Negatives: 0\n",
      "True Positives: 245 \n",
      "\n",
      "Model:  logreg + tf\n",
      "Best Params:  {'tf__ngram_range': (1, 2), 'tf__stop_words': 'english'}\n",
      "0.9992942836979535 \n",
      "\n",
      "0.6659619450317125 \n",
      "\n",
      "True Negatives: 126\n",
      "False Positives: 102\n",
      "False Negatives: 56\n",
      "True Positives: 189 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through index of number of steps\n",
    "for i in range(len(steps_list_tf)):\n",
    "    # instantiate pipeline \n",
    "    pipe = Pipeline(steps=steps_list_tf[i])\n",
    "    # fit GridSearchCV to model and model's params\n",
    "    gs = GridSearchCV(pipe, pipe_params_tf[i], cv=3) \n",
    "\n",
    "    model_results = {}\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    print('Model: ', steps_titles_tf[i])\n",
    "    model_results['model'] = steps_titles_tf[i]\n",
    "\n",
    "    print('Best Params: ', gs.best_params_)\n",
    "    model_results['best_params'] = gs.best_params_\n",
    "\n",
    "    print(gs.score(X_train, y_train), '\\n')\n",
    "    model_results['train_accuracy'] = gs.score(X_train, y_train)\n",
    "    \n",
    "    print(gs.score(X_test, y_test), '\\n')\n",
    "    model_results['test_accuracy'] = gs.score(X_test, y_test)\n",
    "    \n",
    "    model_results['baseline_accuracy'] = baseline\n",
    "\n",
    "    # Display the confusion matrix results showing true/false positive/negative\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, gs.predict(X_test)).ravel() \n",
    "    print(\"True Negatives: %s\" % tn)\n",
    "    print(\"False Positives: %s\" % fp)\n",
    "    print(\"False Negatives: %s\" % fn)\n",
    "    print(\"True Positives: %s\" % tp, '\\n')\n",
    "    \n",
    "    model_results['recall'] = tp/(tp+fn)\n",
    "    model_results['precision'] = tp/(tp+fp)\n",
    "    model_results['f1-score'] = 2*((tp/(tp+fp))*(tp/(tp+fn)))/((tp/(tp+fp))+(tp/(tp+fn)))\n",
    "\n",
    "    gs_results_tf = gs_results_tf.append(model_results, ignore_index=True)\n",
    "    pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>baseline_accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multi_nb + tf</td>\n",
       "      <td>{'tf__ngram_range': (1, 1), 'tf__stop_words': 'english'}</td>\n",
       "      <td>0.941426</td>\n",
       "      <td>0.714588</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg + tf</td>\n",
       "      <td>{'tf__ngram_range': (1, 2), 'tf__stop_words': 'english'}</td>\n",
       "      <td>0.999294</td>\n",
       "      <td>0.665962</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.705224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn + tf</td>\n",
       "      <td>{'tf__ngram_range': (1, 1), 'tf__stop_words': 'english'}</td>\n",
       "      <td>0.517290</td>\n",
       "      <td>0.517970</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.517970</td>\n",
       "      <td>0.682451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model                                               best_params  \\\n",
       "0  multi_nb + tf  {'tf__ngram_range': (1, 1), 'tf__stop_words': 'english'}   \n",
       "2    logreg + tf  {'tf__ngram_range': (1, 2), 'tf__stop_words': 'english'}   \n",
       "1       knn + tf  {'tf__ngram_range': (1, 1), 'tf__stop_words': 'english'}   \n",
       "\n",
       "   train_accuracy  test_accuracy  baseline_accuracy    recall  precision  \\\n",
       "0        0.941426       0.714588            0.51729  0.795918   0.696429   \n",
       "2        0.999294       0.665962            0.51729  0.771429   0.649485   \n",
       "1        0.517290       0.517970            0.51729  1.000000   0.517970   \n",
       "\n",
       "   f1-score  \n",
       "0  0.742857  \n",
       "2  0.705224  \n",
       "1  0.682451  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results_tf.sort_values('test_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the result from CountVectorizer, Multinomial NB gave the highest test accuracy. The training data is still highly overfitted for both Multinomial NB and Logistic Regression but both still did better than the baseline. \n",
    "However, comparing the test accuracy between Multinomial NB + Tfidf Vectorizer against Multinomial NB + Count Vectorizer, the accuracy for the former is higher. \n",
    "\n",
    "CountVectorizer gives a vector with the number of times each word appears in the document. This leads to the problem of having common words that appear most of the time being weighted higher than other words that carry the topic information. Tfidf balances out the term frequency with its inverse document frequency which means that common words that occur across documents will have lower scores than when using CountVectorizer. Thus, the Tfidf is better able to identify words that are important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>baseline_accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>multi_nb + tf</td>\n",
       "      <td>{'tf__ngram_range': (1, 1), 'tf__stop_words': 'english'}</td>\n",
       "      <td>0.941426</td>\n",
       "      <td>0.714588</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multi_nb + cv</td>\n",
       "      <td>{'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}</td>\n",
       "      <td>0.917431</td>\n",
       "      <td>0.693446</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>0.726531</td>\n",
       "      <td>0.695312</td>\n",
       "      <td>0.710579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>logreg + tf</td>\n",
       "      <td>{'tf__ngram_range': (1, 2), 'tf__stop_words': 'english'}</td>\n",
       "      <td>0.999294</td>\n",
       "      <td>0.665962</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.705224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg + cv</td>\n",
       "      <td>{'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}</td>\n",
       "      <td>0.999294</td>\n",
       "      <td>0.625793</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.657640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn + cv</td>\n",
       "      <td>{'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}</td>\n",
       "      <td>0.533522</td>\n",
       "      <td>0.517970</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>0.987755</td>\n",
       "      <td>0.518201</td>\n",
       "      <td>0.679775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>knn + tf</td>\n",
       "      <td>{'tf__ngram_range': (1, 1), 'tf__stop_words': 'english'}</td>\n",
       "      <td>0.517290</td>\n",
       "      <td>0.517970</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.517970</td>\n",
       "      <td>0.682451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model                                               best_params  \\\n",
       "3  multi_nb + tf  {'tf__ngram_range': (1, 1), 'tf__stop_words': 'english'}   \n",
       "0  multi_nb + cv  {'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}   \n",
       "5    logreg + tf  {'tf__ngram_range': (1, 2), 'tf__stop_words': 'english'}   \n",
       "2    logreg + cv  {'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}   \n",
       "1       knn + cv  {'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}   \n",
       "4       knn + tf  {'tf__ngram_range': (1, 1), 'tf__stop_words': 'english'}   \n",
       "\n",
       "   train_accuracy  test_accuracy  baseline_accuracy    recall  precision  \\\n",
       "3        0.941426       0.714588            0.51729  0.795918   0.696429   \n",
       "0        0.917431       0.693446            0.51729  0.726531   0.695312   \n",
       "5        0.999294       0.665962            0.51729  0.771429   0.649485   \n",
       "2        0.999294       0.625793            0.51729  0.693878   0.625000   \n",
       "1        0.533522       0.517970            0.51729  0.987755   0.518201   \n",
       "4        0.517290       0.517970            0.51729  1.000000   0.517970   \n",
       "\n",
       "   f1-score  \n",
       "3  0.742857  \n",
       "0  0.710579  \n",
       "5  0.705224  \n",
       "2  0.657640  \n",
       "1  0.679775  \n",
       "4  0.682451  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the dataframes containing results from both vectorizations\n",
    "results_lem = pd.concat([gs_results_cv, gs_results_tf], ignore_index=True)\n",
    "results_lem.sort_values('test_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split (Stemmed Posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set feature as posts that were stemmed and y for the subreddit suicide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_prep['post_stem']\n",
    "y = df_prep['suicide']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in X_train: 1417\n",
      "Number of rows in y_train: 1417\n",
      "Number of rows in X_test: 473\n",
      "Number of rows in y_test: 473\n"
     ]
    }
   ],
   "source": [
    "# Check the length to confirm that train and test variables have the same length\n",
    "print('Number of rows in X_train: {}'. format(len(X_train)))\n",
    "print('Number of rows in y_train: {}'. format(len(y_train)))\n",
    "print('Number of rows in X_test: {}'. format(len(X_test)))\n",
    "print('Number of rows in y_test: {}'. format(len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV\n",
    "\n",
    "A model will be run for the following classifiers:\n",
    "\n",
    "* Multinomial Naive Bayes\n",
    "* K-Nearest Neighbors\n",
    "* Logistic Regression\n",
    "\n",
    "The results will be displayed, then stored into a DataFrame for a final comparison with the lemmatized posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline steps for each combination of model\n",
    "# Include standard scaler for knn and logistic regression because distance are important when classifying\n",
    "steps_list_cv_st = [ \n",
    "    [('cv', CountVectorizer()),('multi_nb', MultinomialNB())],\n",
    "    [('cv', CountVectorizer()),('scaler', StandardScaler(with_mean=False)),('knn', KNeighborsClassifier())], \n",
    "    [('cv', CountVectorizer()),('scaler', StandardScaler(with_mean=False)),('logreg', LogisticRegression())]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_titles_cv_st = ['multi_nb + cv','knn + cv','logreg + cv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params_cv_st = [\n",
    "    {'cv__stop_words':['english'], 'cv__ngram_range':[(1,1),(1,2)]},\n",
    "    {'cv__stop_words':['english'], 'cv__ngram_range':[(1,1),(1,2)]},\n",
    "    {'cv__stop_words':['english'], 'cv__ngram_range':[(1,1),(1,2)]}\n",
    "]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>baseline_accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, best_params, train_accuracy, test_accuracy, baseline_accuracy, recall, precision, f1-score]\n",
       "Index: []"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate results DataFrame for CountVectorizer\n",
    "gs_results_cv_st = pd.DataFrame(columns=['model','best_params','train_accuracy','test_accuracy',\n",
    "                                      'baseline_accuracy','recall', 'precision', 'f1-score'])\n",
    "gs_results_cv_st.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  multi_nb + cv\n",
      "Best Params:  {'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}\n",
      "0.8969654199011997 \n",
      "\n",
      "0.6976744186046512 \n",
      "\n",
      "True Negatives: 152\n",
      "False Positives: 76\n",
      "False Negatives: 67\n",
      "True Positives: 178 \n",
      "\n",
      "Model:  knn + cv\n",
      "Best Params:  {'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}\n",
      "0.534227240649259 \n",
      "\n",
      "0.5285412262156448 \n",
      "\n",
      "True Negatives: 7\n",
      "False Positives: 221\n",
      "False Negatives: 2\n",
      "True Positives: 243 \n",
      "\n",
      "Model:  logreg + cv\n",
      "Best Params:  {'cv__ngram_range': (1, 2), 'cv__stop_words': 'english'}\n",
      "0.9992942836979535 \n",
      "\n",
      "0.6300211416490487 \n",
      "\n",
      "True Negatives: 77\n",
      "False Positives: 151\n",
      "False Negatives: 24\n",
      "True Positives: 221 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through index of number of steps\n",
    "for i in range(len(steps_list_cv_st)):\n",
    "    # instantiate pipeline \n",
    "    pipe = Pipeline(steps=steps_list_cv_st[i])\n",
    "    # fit GridSearchCV to model and model's params\n",
    "    gs = GridSearchCV(pipe, pipe_params_cv_st[i], cv=3) \n",
    "\n",
    "    model_results = {}\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    print('Model: ', steps_titles_cv_st[i])\n",
    "    model_results['model'] = steps_titles_cv_st[i]\n",
    "\n",
    "    print('Best Params: ', gs.best_params_)\n",
    "    model_results['best_params'] = gs.best_params_\n",
    "\n",
    "    print(gs.score(X_train, y_train), '\\n')\n",
    "    model_results['train_accuracy'] = gs.score(X_train, y_train)\n",
    "    \n",
    "    print(gs.score(X_test, y_test), '\\n')\n",
    "    model_results['test_accuracy'] = gs.score(X_test, y_test)\n",
    "    \n",
    "    model_results['baseline_accuracy'] = baseline\n",
    "    \n",
    "    # Display the confusion matrix results showing true/false positive/negative\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, gs.predict(X_test)).ravel() \n",
    "    print(\"True Negatives: %s\" % tn)\n",
    "    print(\"False Positives: %s\" % fp)\n",
    "    print(\"False Negatives: %s\" % fn)\n",
    "    print(\"True Positives: %s\" % tp, '\\n')\n",
    "    \n",
    "    model_results['recall'] = tp/(tp+fn)\n",
    "    model_results['precision'] = tp/(tp+fp)\n",
    "    model_results['f1-score'] = 2*((tp/(tp+fp))*(tp/(tp+fn)))/((tp/(tp+fp))+(tp/(tp+fn)))\n",
    "    \n",
    "    gs_results_cv_st = gs_results_cv_st.append(model_results, ignore_index=True)\n",
    "    pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>baseline_accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multi_nb + cv</td>\n",
       "      <td>{'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}</td>\n",
       "      <td>0.896965</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>0.726531</td>\n",
       "      <td>0.700787</td>\n",
       "      <td>0.713427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg + cv</td>\n",
       "      <td>{'cv__ngram_range': (1, 2), 'cv__stop_words': 'english'}</td>\n",
       "      <td>0.999294</td>\n",
       "      <td>0.630021</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>0.902041</td>\n",
       "      <td>0.594086</td>\n",
       "      <td>0.716370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn + cv</td>\n",
       "      <td>{'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}</td>\n",
       "      <td>0.534227</td>\n",
       "      <td>0.528541</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>0.991837</td>\n",
       "      <td>0.523707</td>\n",
       "      <td>0.685472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model                                               best_params  \\\n",
       "0  multi_nb + cv  {'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}   \n",
       "2    logreg + cv  {'cv__ngram_range': (1, 2), 'cv__stop_words': 'english'}   \n",
       "1       knn + cv  {'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}   \n",
       "\n",
       "   train_accuracy  test_accuracy  baseline_accuracy    recall  precision  \\\n",
       "0        0.896965       0.697674            0.51729  0.726531   0.700787   \n",
       "2        0.999294       0.630021            0.51729  0.902041   0.594086   \n",
       "1        0.534227       0.528541            0.51729  0.991837   0.523707   \n",
       "\n",
       "   f1-score  \n",
       "0  0.713427  \n",
       "2  0.716370  \n",
       "1  0.685472  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results_cv_st.sort_values('test_accuracy',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result from using stemmed data is almost the same as the results from using lemmatized data. Multinomial NB remains the best performing but with a little less overfitting than the one with lemmatized data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_list_tf_st = [ # list of pipeline steps for each model combo\n",
    "    [('tf',TfidfVectorizer()),('multi_nb',MultinomialNB())],\n",
    "    [('tf',TfidfVectorizer()),('scaler',StandardScaler(with_mean=False)),('knn',KNeighborsClassifier())], \n",
    "    [('tf',TfidfVectorizer()),('scaler',StandardScaler(with_mean=False)),('logreg',LogisticRegression())]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_titles_tf_st = ['multi_nb + tf','knn + tf','logreg + tf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params_tf_st = [\n",
    "    {\"tf__stop_words\":['english'], \"tf__ngram_range\":[(1,1),(1,2)]},\n",
    "    {\"tf__stop_words\":['english'], \"tf__ngram_range\":[(1,1),(1,2)]},\n",
    "    {\"tf__stop_words\":['english'], \"tf__ngram_range\":[(1,1),(1,2)]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>baseline_accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, best_params, train_accuracy, test_accuracy, baseline_accuracy, recall, precision, f1-score]\n",
       "Index: []"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate results DataFrame\n",
    "gs_results_tf_st = pd.DataFrame(columns=['model','best_params','train_accuracy','test_accuracy','baseline_accuracy',\n",
    "                                         'recall', 'precision', 'f1-score'])\n",
    "gs_results_tf_st.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  multi_nb + tf\n",
      "Best Params:  {'tf__ngram_range': (1, 2), 'tf__stop_words': 'english'}\n",
      "0.9943542695836274 \n",
      "\n",
      "0.7124735729386892 \n",
      "\n",
      "True Negatives: 156\n",
      "False Positives: 72\n",
      "False Negatives: 64\n",
      "True Positives: 181 \n",
      "\n",
      "Model:  knn + tf\n",
      "Best Params:  {'tf__ngram_range': (1, 1), 'tf__stop_words': 'english'}\n",
      "0.5172900494001411 \n",
      "\n",
      "0.5179704016913319 \n",
      "\n",
      "True Negatives: 0\n",
      "False Positives: 228\n",
      "False Negatives: 0\n",
      "True Positives: 245 \n",
      "\n",
      "Model:  logreg + tf\n",
      "Best Params:  {'tf__ngram_range': (1, 2), 'tf__stop_words': 'english'}\n",
      "0.9992942836979535 \n",
      "\n",
      "0.6659619450317125 \n",
      "\n",
      "True Negatives: 133\n",
      "False Positives: 95\n",
      "False Negatives: 63\n",
      "True Positives: 182 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through index of number of steps\n",
    "for i in range(len(steps_list_tf_st)):\n",
    "    # instantiate pipeline \n",
    "    pipe = Pipeline(steps=steps_list_tf_st[i])\n",
    "    # fit GridSearchCV to model and model's params\n",
    "    gs = GridSearchCV(pipe, pipe_params_tf_st[i], cv=3) \n",
    "\n",
    "    model_results = {}\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    print('Model: ', steps_titles_tf_st[i])\n",
    "    model_results['model'] = steps_titles_tf_st[i]\n",
    "\n",
    "    print('Best Params: ', gs.best_params_)\n",
    "    model_results['best_params'] = gs.best_params_\n",
    "\n",
    "    print(gs.score(X_train, y_train), '\\n')\n",
    "    model_results['train_accuracy'] = gs.score(X_train, y_train)\n",
    "    \n",
    "    print(gs.score(X_test, y_test), '\\n')\n",
    "    model_results['test_accuracy'] = gs.score(X_test, y_test)\n",
    "    \n",
    "    model_results['baseline_accuracy'] = baseline\n",
    "\n",
    "    # Display the confusion matrix results showing true/false positive/negative\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, gs.predict(X_test)).ravel() \n",
    "    print(\"True Negatives: %s\" % tn)\n",
    "    print(\"False Positives: %s\" % fp)\n",
    "    print(\"False Negatives: %s\" % fn)\n",
    "    print(\"True Positives: %s\" % tp, '\\n')\n",
    "    \n",
    "    model_results['recall'] = tp/(tp+fn)\n",
    "    model_results['precision'] = tp/(tp+fp)\n",
    "    model_results['f1-score'] = 2*((tp/(tp+fp))*(tp/(tp+fn)))/((tp/(tp+fp))+(tp/(tp+fn)))\n",
    "\n",
    "    gs_results_tf_st = gs_results_tf_st.append(model_results, ignore_index=True)\n",
    "    pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>baseline_accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multi_nb + tf</td>\n",
       "      <td>{'tf__ngram_range': (1, 2), 'tf__stop_words': 'english'}</td>\n",
       "      <td>0.994354</td>\n",
       "      <td>0.712474</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>0.738776</td>\n",
       "      <td>0.715415</td>\n",
       "      <td>0.726908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg + tf</td>\n",
       "      <td>{'tf__ngram_range': (1, 2), 'tf__stop_words': 'english'}</td>\n",
       "      <td>0.999294</td>\n",
       "      <td>0.665962</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.657040</td>\n",
       "      <td>0.697318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn + tf</td>\n",
       "      <td>{'tf__ngram_range': (1, 1), 'tf__stop_words': 'english'}</td>\n",
       "      <td>0.517290</td>\n",
       "      <td>0.517970</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.517970</td>\n",
       "      <td>0.682451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model                                               best_params  \\\n",
       "0  multi_nb + tf  {'tf__ngram_range': (1, 2), 'tf__stop_words': 'english'}   \n",
       "2    logreg + tf  {'tf__ngram_range': (1, 2), 'tf__stop_words': 'english'}   \n",
       "1       knn + tf  {'tf__ngram_range': (1, 1), 'tf__stop_words': 'english'}   \n",
       "\n",
       "   train_accuracy  test_accuracy  baseline_accuracy    recall  precision  \\\n",
       "0        0.994354       0.712474            0.51729  0.738776   0.715415   \n",
       "2        0.999294       0.665962            0.51729  0.742857   0.657040   \n",
       "1        0.517290       0.517970            0.51729  1.000000   0.517970   \n",
       "\n",
       "   f1-score  \n",
       "0  0.726908  \n",
       "2  0.697318  \n",
       "1  0.682451  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results_tf_st.sort_values('test_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial NB again is the best model with the highest accuracy but is very highly overfitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>baseline_accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>multi_nb + tf</td>\n",
       "      <td>{'tf__ngram_range': (1, 2), 'tf__stop_words': 'english'}</td>\n",
       "      <td>0.994354</td>\n",
       "      <td>0.712474</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>0.738776</td>\n",
       "      <td>0.715415</td>\n",
       "      <td>0.726908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multi_nb + cv</td>\n",
       "      <td>{'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}</td>\n",
       "      <td>0.896965</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>0.726531</td>\n",
       "      <td>0.700787</td>\n",
       "      <td>0.713427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>logreg + tf</td>\n",
       "      <td>{'tf__ngram_range': (1, 2), 'tf__stop_words': 'english'}</td>\n",
       "      <td>0.999294</td>\n",
       "      <td>0.665962</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.657040</td>\n",
       "      <td>0.697318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg + cv</td>\n",
       "      <td>{'cv__ngram_range': (1, 2), 'cv__stop_words': 'english'}</td>\n",
       "      <td>0.999294</td>\n",
       "      <td>0.630021</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>0.902041</td>\n",
       "      <td>0.594086</td>\n",
       "      <td>0.716370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn + cv</td>\n",
       "      <td>{'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}</td>\n",
       "      <td>0.534227</td>\n",
       "      <td>0.528541</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>0.991837</td>\n",
       "      <td>0.523707</td>\n",
       "      <td>0.685472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>knn + tf</td>\n",
       "      <td>{'tf__ngram_range': (1, 1), 'tf__stop_words': 'english'}</td>\n",
       "      <td>0.517290</td>\n",
       "      <td>0.517970</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.517970</td>\n",
       "      <td>0.682451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model                                               best_params  \\\n",
       "3  multi_nb + tf  {'tf__ngram_range': (1, 2), 'tf__stop_words': 'english'}   \n",
       "0  multi_nb + cv  {'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}   \n",
       "5    logreg + tf  {'tf__ngram_range': (1, 2), 'tf__stop_words': 'english'}   \n",
       "2    logreg + cv  {'cv__ngram_range': (1, 2), 'cv__stop_words': 'english'}   \n",
       "1       knn + cv  {'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}   \n",
       "4       knn + tf  {'tf__ngram_range': (1, 1), 'tf__stop_words': 'english'}   \n",
       "\n",
       "   train_accuracy  test_accuracy  baseline_accuracy    recall  precision  \\\n",
       "3        0.994354       0.712474            0.51729  0.738776   0.715415   \n",
       "0        0.896965       0.697674            0.51729  0.726531   0.700787   \n",
       "5        0.999294       0.665962            0.51729  0.742857   0.657040   \n",
       "2        0.999294       0.630021            0.51729  0.902041   0.594086   \n",
       "1        0.534227       0.528541            0.51729  0.991837   0.523707   \n",
       "4        0.517290       0.517970            0.51729  1.000000   0.517970   \n",
       "\n",
       "   f1-score  \n",
       "3  0.726908  \n",
       "0  0.713427  \n",
       "5  0.697318  \n",
       "2  0.716370  \n",
       "1  0.685472  \n",
       "4  0.682451  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the dataframes containing results from both vectorizations\n",
    "results_stem = pd.concat([gs_results_cv_st, gs_results_tf_st], ignore_index=True)\n",
    "results_stem.sort_values('test_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>baseline_accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>multi_nb + tf</td>\n",
       "      <td>{'tf__ngram_range': (1, 1), 'tf__stop_words': 'english'}</td>\n",
       "      <td>0.941426</td>\n",
       "      <td>0.714588</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multi_nb + cv</td>\n",
       "      <td>{'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}</td>\n",
       "      <td>0.917431</td>\n",
       "      <td>0.693446</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>0.726531</td>\n",
       "      <td>0.695312</td>\n",
       "      <td>0.710579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>logreg + tf</td>\n",
       "      <td>{'tf__ngram_range': (1, 2), 'tf__stop_words': 'english'}</td>\n",
       "      <td>0.999294</td>\n",
       "      <td>0.665962</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.705224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg + cv</td>\n",
       "      <td>{'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}</td>\n",
       "      <td>0.999294</td>\n",
       "      <td>0.625793</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.657640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn + cv</td>\n",
       "      <td>{'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}</td>\n",
       "      <td>0.533522</td>\n",
       "      <td>0.517970</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>0.987755</td>\n",
       "      <td>0.518201</td>\n",
       "      <td>0.679775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>knn + tf</td>\n",
       "      <td>{'tf__ngram_range': (1, 1), 'tf__stop_words': 'english'}</td>\n",
       "      <td>0.517290</td>\n",
       "      <td>0.517970</td>\n",
       "      <td>0.51729</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.517970</td>\n",
       "      <td>0.682451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model                                               best_params  \\\n",
       "3  multi_nb + tf  {'tf__ngram_range': (1, 1), 'tf__stop_words': 'english'}   \n",
       "0  multi_nb + cv  {'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}   \n",
       "5    logreg + tf  {'tf__ngram_range': (1, 2), 'tf__stop_words': 'english'}   \n",
       "2    logreg + cv  {'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}   \n",
       "1       knn + cv  {'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}   \n",
       "4       knn + tf  {'tf__ngram_range': (1, 1), 'tf__stop_words': 'english'}   \n",
       "\n",
       "   train_accuracy  test_accuracy  baseline_accuracy    recall  precision  \\\n",
       "3        0.941426       0.714588            0.51729  0.795918   0.696429   \n",
       "0        0.917431       0.693446            0.51729  0.726531   0.695312   \n",
       "5        0.999294       0.665962            0.51729  0.771429   0.649485   \n",
       "2        0.999294       0.625793            0.51729  0.693878   0.625000   \n",
       "1        0.533522       0.517970            0.51729  0.987755   0.518201   \n",
       "4        0.517290       0.517970            0.51729  1.000000   0.517970   \n",
       "\n",
       "   f1-score  \n",
       "3  0.742857  \n",
       "0  0.710579  \n",
       "5  0.705224  \n",
       "2  0.657640  \n",
       "1  0.679775  \n",
       "4  0.682451  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare with the above result\n",
    "results_lem.sort_values('test_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the best performing model i.e. Multinomial NB with Tfidf Vectorizer, the lemmatized data performed only marginally better in terms of accuracy. However, given the context of the problem at hand, we would want to maximise recall as much as possible since it shows the models ability to find all the data points of interest i.e. all the suicide posts. If recall is low, it means that red flags would not be raised for those who are suicidal even when they are actually suicidal. The following models seem to do better in terms of recall and accuracy:\n",
    "1. Lemmatized Tfidf Multinomial NB\n",
    "    * tf__ngram_range=(1,1)\n",
    "    * tf__stop_words='english'\n",
    "2. Lemmatized Tfidf Scaled Logistic Regression\n",
    "    * tf__ngram_range=(1,2)\n",
    "    * tf__stop_words='english'\n",
    "    \n",
    "We will optimise these models and pick the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimising Tfidf Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset X and y so that we use the lemmatized posts instead of stemmed posts. Train/test split again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_prep['post_lem']\n",
    "y = df_prep['suicide']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dataframe to store results for Multinomial NB model tweaks\n",
    "mnb_runs = pd.DataFrame(columns=['train_accuracy','test_accuracy','best_params','recall',\n",
    "                                 'precision','f1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Pipeline with fixed parameters from the earlier run\n",
    "mnb_pipe = Pipeline([('tf',TfidfVectorizer(stop_words='english', ngram_range=(1,1))),\n",
    "                 ('mnb',MultinomialNB())\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for GridSearch using Pipeline, formatted to call named estimators\n",
    "mnb_params = {'mnb__alpha': np.arange(1,1.5,.1),\n",
    "              'tf__max_features': [2000, 2500, 3000],\n",
    "              'tf__min_df': [2, 3], \n",
    "              'tf__max_df': [.4, 0.45, 0.55]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.8701482004234298\n",
      "Test Accuracy:  0.693446088794926\n",
      "Best Params:  {'mnb__alpha': 1.4000000000000004, 'tf__max_df': 0.45, 'tf__max_features': 3000, 'tf__min_df': 2}\n"
     ]
    }
   ],
   "source": [
    "# Empty dictionary to store results\n",
    "mnb_results = {} \n",
    "\n",
    "mnb_gs = GridSearchCV(mnb_pipe, mnb_params, cv=5)\n",
    "mnb_gs.fit(X_train, y_train)\n",
    "\n",
    "print('Train Accuracy: ', mnb_gs.score(X_train, y_train))\n",
    "mnb_results['train_accuracy'] = mnb_gs.score(X_train, y_train)\n",
    "\n",
    "print('Test Accuracy: ',mnb_gs.score(X_test, y_test))\n",
    "mnb_results['test_accuracy'] = mnb_gs.score(X_test, y_test)\n",
    "\n",
    "print('Best Params: ',mnb_gs.best_params_)\n",
    "mnb_results['best_params'] = mnb_gs.best_params_ \n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, mnb_gs.predict(X_test)).ravel()\n",
    "mnb_results['recall'] = tp/(tp+fn)\n",
    "mnb_results['precision'] = tp/(tp+fp)\n",
    "mnb_results['f1-score'] = 2*((tp/(tp+fp))*(tp/(tp+fn)))/((tp/(tp+fp))+(tp/(tp+fn)))\n",
    "\n",
    "mnb_runs = mnb_runs.append(mnb_results, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>best_params</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.870148</td>\n",
       "      <td>0.693446</td>\n",
       "      <td>{'mnb__alpha': 1.4000000000000004, 'tf__max_df': 0.45, 'tf__max_features': 3000, 'tf__min_df': 2}</td>\n",
       "      <td>0.808163</td>\n",
       "      <td>0.668919</td>\n",
       "      <td>0.731978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_accuracy  test_accuracy  \\\n",
       "0        0.870148       0.693446   \n",
       "\n",
       "                                                                                         best_params  \\\n",
       "0  {'mnb__alpha': 1.4000000000000004, 'tf__max_df': 0.45, 'tf__max_features': 3000, 'tf__min_df': 2}   \n",
       "\n",
       "     recall  precision  f1-score  \n",
       "0  0.808163   0.668919  0.731978  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimising Tfidf Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dataframe to store results for Logistic Regression model tweaks\n",
    "lr_runs = pd.DataFrame(columns=['train_accuracy','test_accuracy','best_params','recall',\n",
    "                                'precision','f1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Pipeline with fixed parameters from the earlier run\n",
    "lr_pipe = Pipeline([('tf',TfidfVectorizer(stop_words='english', ngram_range=(1,2))),\n",
    "                 ('scaler',StandardScaler(with_mean=False)),('lr',LogisticRegression(solver='liblinear'))\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for GridSearch using Pipeline\n",
    "lr_params = {'tf__max_features': [1000,2000, 2500],\n",
    "             'tf__min_df': [2, 3], \n",
    "             'tf__max_df': [0.7, 0.75, 0.8],\n",
    "             'lr__penalty': ['l1', 'l2'],\n",
    "             'lr__class_weight': [None, 'balanced']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9992942836979535\n",
      "Test Accuracy:  0.6448202959830867\n",
      "Best Params:  {'lr__class_weight': None, 'lr__penalty': 'l1', 'tf__max_df': 0.8, 'tf__max_features': 2500, 'tf__min_df': 2}\n"
     ]
    }
   ],
   "source": [
    "# Empty dictionary to store results\n",
    "lr_results = {} \n",
    "\n",
    "lr_gs = GridSearchCV(lr_pipe, lr_params, cv=5)\n",
    "lr_gs.fit(X_train, y_train)\n",
    "\n",
    "print('Train Accuracy: ', lr_gs.score(X_train, y_train))\n",
    "lr_results['train_accuracy'] = lr_gs.score(X_train, y_train)\n",
    "\n",
    "print('Test Accuracy: ',lr_gs.score(X_test, y_test))\n",
    "lr_results['test_accuracy'] = lr_gs.score(X_test, y_test)\n",
    "\n",
    "print('Best Params: ',lr_gs.best_params_)\n",
    "lr_results['best_params'] = lr_gs.best_params_ \n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, lr_gs.predict(X_test)).ravel()\n",
    "lr_results['recall'] = tp/(tp+fn)\n",
    "lr_results['precision'] = tp/(tp+fp)\n",
    "lr_results['f1-score'] = 2*((tp/(tp+fp))*(tp/(tp+fn)))/((tp/(tp+fp))+(tp/(tp+fn)))\n",
    "\n",
    "lr_runs = lr_runs.append(lr_results, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>best_params</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999294</td>\n",
       "      <td>0.64482</td>\n",
       "      <td>{'lr__class_weight': None, 'lr__penalty': 'l1', 'tf__max_df': 0.8, 'tf__max_features': 2500, 'tf__min_df': 2}</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.646388</td>\n",
       "      <td>0.669291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_accuracy  test_accuracy  \\\n",
       "0        0.999294        0.64482   \n",
       "\n",
       "                                                                                                     best_params  \\\n",
       "0  {'lr__class_weight': None, 'lr__penalty': 'l1', 'tf__max_df': 0.8, 'tf__max_features': 2500, 'tf__min_df': 2}   \n",
       "\n",
       "     recall  precision  f1-score  \n",
       "0  0.693878   0.646388  0.669291  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the multiple runs of searching for the best parameters, the one selected as the production model is **Tfidf Vectorization with Multinomial Naive Bayes** with the following parameters:\n",
    "* 'mnb__alpha': 1.4000000000000004,\n",
    "* 'tf__max_df': 0.45\n",
    "* 'tf__max_features': 3000\n",
    "* 'tf__min_df': 2\n",
    "* 'tf__stop_words': 'english'\n",
    "* 'tf__ngram_range': (1,1)\n",
    "\n",
    "Although the accuracy is lower than that of the same model in the first run earlier in the notebook, the recall is a little higher at 0.81 compared to 0.79. It also is less overfitted, so it should generalise better to unseen data. This model is also better than the Logistic Regression in terms of recall, with a recall of 0.81 for the former and 0.69 for the latter. \n",
    "\n",
    "The model is chosen mainly based on recall since the idea of false positives is far better than false negatives. The occurrence of false negatives should be minimised because if we fail to identify potentially suicidal individuals, we would not be giving them the care and treatment needed, which can result in a loss of lives. Precision is not as important; even if we are not able to maximise it, which translates to a higher number of false positives, we are only giving extra care and attention to those who are depressed and not potentially suicidal. They may, in fact, benefit from this extra attention. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.693446088794926"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate model with best parameters.\n",
    "tf_final = TfidfVectorizer(max_df=0.45, max_features=3000, min_df=2, \n",
    "                             stop_words='english', ngram_range=(1,1))\n",
    "X_train_final = tf_final.fit_transform(X_train).todense()\n",
    "X_test_final = tf_final.transform(X_test).todense()\n",
    "\n",
    "# Fit model.\n",
    "mnb_final = MultinomialNB(alpha=1.4000000000000004)\n",
    "mnb_final.fit(X_train_final, y_train)\n",
    "mnb_final.score(X_test_final, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data frame to compare the predicted class versus the actual class. We will look through the inaccurately predicted texts to pick out some pattern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval = pd.DataFrame(X_test)\n",
    "model_eval['suicide'] = y_test\n",
    "model_eval['predictions'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_lem</th>\n",
       "      <th>suicide</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>birthday  tomorrowi recently   go   hospital per  therapist  get ivcd    month ago  nothing  gotten better  med  helped   still find  planning  death  psychiatrist prescribes  ambien    googled  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>way  recover    live    struggling  depression social anxiety etc sometimes  wish  would  transformed  another person    normal  want  live  good life     want  live  life  carrying pain everyd...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>depression feel likei   put   word   time  depression   feel like  go  life   tight tight pressure  squeezing   heart  day long      ignore   go throughout  day  nobody knowing   going     snap  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>bad person  step grandmother    extremely abusive  toxic     mother    life got diagnosed  cancer last year    terminal   time however   required u  dedicate much   time     longer   car  whate...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>fucking reasoni cant stand   dont wanna kill    really hope  pray   car run   fuck    rib   gunpoint    ask    fucking shoot    mother   seem  get  shes pulling   depressed  know   depressed  k...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                     post_lem  \\\n",
       "516    birthday  tomorrowi recently   go   hospital per  therapist  get ivcd    month ago  nothing  gotten better  med  helped   still find  planning  death  psychiatrist prescribes  ambien    googled  ...   \n",
       "41       way  recover    live    struggling  depression social anxiety etc sometimes  wish  would  transformed  another person    normal  want  live  good life     want  live  life  carrying pain everyd...   \n",
       "1432   depression feel likei   put   word   time  depression   feel like  go  life   tight tight pressure  squeezing   heart  day long      ignore   go throughout  day  nobody knowing   going     snap  ...   \n",
       "754      bad person  step grandmother    extremely abusive  toxic     mother    life got diagnosed  cancer last year    terminal   time however   required u  dedicate much   time     longer   car  whate...   \n",
       "1824     fucking reasoni cant stand   dont wanna kill    really hope  pray   car run   fuck    rib   gunpoint    ask    fucking shoot    mother   seem  get  shes pulling   depressed  know   depressed  k...   \n",
       "\n",
       "      suicide  predictions  \n",
       "516         1            1  \n",
       "41          1            1  \n",
       "1432        0            0  \n",
       "754         1            1  \n",
       "1824        0            1  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dataframe\n",
    "model_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pick out the false negatives\n",
    "fn = model_eval[model_eval['suicide'] == 1][model_eval['predictions'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of false negatives are 47 out of 473 posts.\n"
     ]
    }
   ],
   "source": [
    "print('The number of false negatives are {} out of {} posts.'.format(fn.shape[0], model_eval.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_lem</th>\n",
       "      <th>suicide</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>everyone   backstabbing sack  shit</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>depression  got worse   lost  cati  got better  little bit    drinking  cry nonstop     beside cutting   drinking alcohol</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>anyone  wanna talk     sorry   error english   first language     anxious right     long story    kind  confusing    go   depressed since ever    know   started    started   thing   know     depressed since    kid  thing  getting worse  worse    big crisis   last two year life      expecting    thing   complicated  tried tried    still  fucked  thing   cousin life  another country   asked    could stay    3 month  thing get better    organize   live    moved  one month ago    trying  build thing  live  maybe another country another life maybe thing get better    know   trying   asked     stay   home   really kind  supportive    august 2019   got  last month     nice    wake    purpose  say bad thing like   watch  tv cause   sleeping   couch  couch   bed   insinuated    find  place   since  day  arrived   try    help  thing  clean  house  wash  clothes  go  supermarket  buy  food  cook  food  try   outside     give   space  still   acting bad towards     know    since  asked      3 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>well  see   fun   worldnothing aint fun nomore nothing excites  nomore nothing  look foward  nomore life aint fun nomore  whats  point  staying</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>find  sense  power  anything   hitting     situation  fucked every one    fucked  hate  fact    headed  nothing   meaningless middle class civilian life   influence  meaning  anyone  get  fucking angry  everything happening   world around      want   forced  play  rigged game   time  feel much authority  anything    body smacking   hard   possibly        suffering like  since   born      long like    want  cry   help         honest   people  know  even    cry   one would listen  like       cry  screaming  loud      pillow   last ten minute    cry screaming animal trapped   cage    processed  meat meat    even  enjoyed  anyone  thrown away</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>old brain  common     life   planet     addition  new   hate     reason   problem fuck new brain</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>bullshitso  went   stupid therapist last week    self harm  suicide thing   school  dont really want help     least hoping   help   mental health  didnt happen instead   going  get tested  autism asperger   dont think   autism  bad     really   wanted  wanted  sort   mental health      take    thing  could mean   autistic   hate   dont get    referred   therapist  specializes  autism      need sorry    offensive sorry</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>feeling suicidali   hospitalised twice  last  week  severe depression suicidal thought  anxiety  fianc    broken       absolute mess     one  someone please tell     ok   broken</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>tired  people saying   get better    constantly  getting worsefucking liar</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>know   talk  anymore    around 6 7    dad got  scholarship  australia   really happy      someone   lot  friend exceptional grade etc   turned 180   came back  australia   home country     know  junior high  pretty average execpt  grade  starting  fall   got  occasional teasing     different english accent  come high school  everything hit real hard  grade   par  dad   allow   hang   friend  started   heli parent  would make irrational night curfew  also got  numerous trouble  school  time   thought   friend left  one  one  even spread  rumor    gay  big    country   top    girlfriend cheated    felt  desolate  unwanted ever since   became socially awkward   started  stutter mumble   speech  thought  jumping   roof  canceled eventually   ate  depression  loneliness     time gaining 10 kilo   making  obese last year  got accepted  uni   city away  home  gave   much needed liberty away   dad  tried making friend   usual stuff   shrugged    cool enough     plain awkward person  kil...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>w  fun ride   lasted</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>turn 32  april  job  friend  girlfriend  life   title say     degree     confidence  suffer  social anxiety    little work experience  lost   friend year ago  romantic interest     leave  house except   morning run  feel totally lost    idea      parent  worried   let    keep asking    plan      answer    want  see  family   birthday   embarassed   something fundamentally wrong     depression maybe     trance   keep repeating   thing day  day   idea   change</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>ehi  usually ok   still hate   often fantasize  death  detailed way anyone else</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>nothingi  lost  fight   nothing   point  ball  emotion barely fucking human   lost  motivation  go     even pushing back   destruction  brain wreck    special unique important smart helpful  human   sense    selfish lying bastard piece  shit   insignificant  background man          fake  fake built   conceal  blackness  horrible person  really      happy ever  everything  put     mask  hide  nothingness nobody need       life  take   point   numb     feel  anymore   tired  waiting fighting disguising  trying   losing    nothing     win    end  doubt  find solace  anything</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>suicidewhen   turn 18  want  kill   feel like     waste  space   friend  staying     pity  every time   think    see  failure   never  able   anything good    asking  advice        lost   mind</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>want  die    actually uselessi got  talent whatsoever  got nothing  want    tried hard  search          good    find    actually hopeless     fucking talent whatsoever  motivation  anything  well    huge disappointment  everyone around    hurt  love  friend  family  want    proud      nothing     proud   recently   tried  best  everything studying socializing class   taking everything    motivation  making  parent  friend proud    useful human     love      loveable  lost  motivation recently   parent said     good enough said  younger sister  better    laughed  got pissed  told    trying  best   told         result grade   evidence  got 2 b   math  social study  0 1  0 2 difference  otherwise    called  dumb    regret spending  much money      going    way  working hard   getting  best result  said    acting depressed   reason    whining   life    spoiled  break  completely  father said   losing motivation  go  work  earn money    wasting    mother said  disappoint     fault     ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>think   woke  one day happy   longer suicidal   probably die   massive heart attack   shock 48m   dealt  depression  suicidal thought  probably 35 year      pretty much   different med  2 round  tm 30 session     therapy nothing  made  feel  better    remember   way  feel  sad hopeless  suicidal    know  much longer   keep going</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>someone talk   please   feeling sick anxious  need  help please</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>would  friend care   died  closest friend   distant lately mostly busy   job  friend  partner  feel    really care      hard  get  contact    gave    depression would  even care    dead</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>give  one reason  carry    life     missing   almost every joy imaginable  never   best friend   never  part   friend group   group   matter  never felt accepted    temporary job   waiter   online chat    class never   girlfriend never kissed never  sex never  someone compliment  never   unforgettable holiday trip never   memorable spring break  summer break never went   cool festival never   great party never hosted one either  list go       feel lonely   depression  physically weighing       motivation   anything     parent say   read    face  legit cannot remember  last time   fun  would  even bother going  like    feel like    surviving  day rather  living   almost tempted  move  another country start anew   go entirely crazy   feel like  would carry    way   even  depressed everyone around    much fun   last week  overheard two normal guy around  age discussing  plan   summer   crazy memory  wanted  kill   badly hearing   missed   fuck</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>help mei   felling kind  sad lately     sure   sub   right one   help   sorry   english  dumb    make  mistake  friend secretly wanted   leave  alone    say  without   hard enough  life   kinda falling apart   need  advice  keep  going  please help</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anyone angry  bitter   time    tolerate anybody  hate  sound   voice child playing car people laughing anything   always sort   loner      tolerate  human presence   point  friend   character  create  people  want  talk      life    fine   nobody   life understands   even care enough  try  understand</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>guy replay  life   head     replaying  entire life   head recently    thinking  lot   childhood       child   experience   mostly positive  feel like  could snap   day   okay       help  think  memory   completely unrelated   depression</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>visit  psychiatrist  16 currently going  depression    talk  anyone    visiting  psychotherapist   2 year   psychiatrist  several week   decided  stop going  like 6 month ago    diagnosed  social anxiety   depression  never actually talked    anyone  even   parent   therapist  everyday life go like  wake  survive 7 hour  school come home play video game  rest   day since     anything better   cry  sleep repeat  school  barely speak  anyone even though   going    class   5 year    1 2 friend   mostly  see    last choice everytime   want  meet    one else  time recently  got someone new   class   seems like    social contact   everyone else   past 3 day     last 5 year everyone think    introverted    kinda true     get rejected  everyone  even try  talk   get excluded  everything  people throw party  never get invited  people  barely talk  get invited  grade  horrible      get   school    even know   want  become since   stopped caring   noticed  everyone ignores    matter  hard  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>life suck   think   something wrong   ever since  came   state  college       depressive state  mind school killed  passion    wanted     shit ton  work  almost  free time    want  change school take  gap year    unable    due  financial reason     friend  school   classmate   feel  like coworkers    concerned      career   friend  family   feel like  family    nightmare  everyone hate    used     optimistic guy   little pessimism    feel like  pessimistic side  taken    think     inner voice  tell     go ahead  kill      easy solution  every single problem    also noticed       original self anymore  lose patience way faster   used   get upset  easily   much   feel like   lost   self    know    anymore everything seems pointless  nothing motivates   work hard  live life anymore   know    act  suicide  understand    wrong  selfish   reason  suicide   reasonable    keep telling        rough patch  life      small hill      climb  school    hand    lot  work  stress piled    amount  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>2 month left           meantime  thought  planting flower  hanging   friend also  try  make  comic btw   suggest getting help  already go   therapist  take ad     handle  life anymore school    hard    constantly feel tired  mark got worse  lost  motivation  keep going    reason     feel like sharing  know maybe   couple  month   feel better thanks  advance</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>wrong   brain  life  okay pretty good  guess wish  made  money    happy       matter  still feel    strong need  kill    last    like  week    short term like   hour sometimes  feel like    slit  wrist   tub  put  bullet   brain  swerve   truck   know better   something   brain   triggering     christian  real one   ask god  time  take      help    like  voice  little guy   shoulder waiting  watching  anything  trigger  uhg  frustrating  think    dog  husband  brother sister  niece  nephew need    voice   care    wondering     part   brain      never done hard core drug   mother  high  speed    pregnant       dopamine issue     drug  fall  deep depression  get suicidal   maybe   hereditary  maybe    drug    pregnant caused  issue   brain anyway  thought would  helpful thank   advance</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>stress  loneliness  dragging   againafter 29 year    shut  sometimes  social anxiety  bad     step   house  go near  window mental health  bad     work  finish school  decided  go back  school   dependent   longtime    make  feel awful    element  abuse   past   dont think   fully trust anyone        die  get  high paying job without  degree  hurting  back    terrible back  neurological problem    left  something like stripping   suicide amp nbsp   point class  getting  intense   already behind   online class  posted  deadline    prioritizing  class    work around 30 hour week  keep  quality high   aiming      class  supposedly graded harshly  far      1 b  something  worked    10 hour anyway    behind   online class  trying  make time  catch   seems impossible amp nbsp    person class   take  much time    4 hour studio  homework take  maybe 1 5 hour usually   trouble managing time   hardly see       see    stay  late   play game  havent   intimacy    month  otherwise   like  1 2x ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>thought  getting back   mindi     told everyone   run away  never come back take   life  f everything life got better   short        take long    lose everything  seemed worth   back  got divorced thrown   flat  whole lot  lawyer bullshit   lot  negative thought basically    truly happy since    thing  turning  shit    feeling   suicidal thought  slowly finding  way back      med  seeking professional help   still feel  lost    time feel like   failing  every little thing   turning away  people  adore    fair   often feel like    torn apart form  inside     surely getting sick      depressed   long    think   sure    hold  together  much longer feel like  rant perhaps   help thank    attention  time</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>im  longer clean   feel  much betteri hate  pain  cuttinf    havent    year   felt  slipping   paranoia attack   really wanted  sleep tonight</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>f24   traumatic experience   ruining  life   lost hope  living please read throwawayacc   extremely depressed  feel like  life  ended  incident  happened  affected  life extremely negatively  lost   friend    longer talk  anyone  go    scared  tell anyone  happened       embarrassed  live       support  anyone  partner  tired   dealing   depression  seems never ending  feel like   ready   end   really    anyone  talk   stay   bed   time   literally ignoring everyone  starve   day sometimes    stay   bed   never ever ever dealt  anything like    life  feel like   lost everything       concerned   loss   baby read story  understand  anything    honestly  denial    happen  feel like    even want  accept    pregnant   living  denial  really need someone  talk    sr think   ready  end  please  would help  someone listened    know  story   bit long   would really appreciate  anyone could  listen   least reply  something kind anything really  apologize  typo  bad grammar    throw away ac...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>tired  acting happy   tired   alivemy whole life   lie   act happy    people expect      fuck could   happy    18     several people u know kill    watched   man drown  death right  front     parent make  go right back   spot   happened right   grandma  house    sleep twenty foot away      told  man   deal   well   fucking tired  pretending    molested   father left     twice    happy    piss     sense  left     awnser  call   never get  see  little sister two      never get  meet   know    good boy   need  smile   pain    happy right     family say      society say        woman      sexual attacked     depressed   sad   fuck</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>ppl say u need help   really mean    fucking problem  feel like  could go week without  contact  ppl   forget  dont know         machine mind   machine world let  go</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>could use someone  talk</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>suicidal hi    sure    one   thing      ask      definite answer     sure    experience  truly suicidal thought     feel sad  become  thankful    try  express  god thanks     given   feel guilty  spending  time self harming   self destructive  feel   never  able  truly convey  thankful       given     back  square one  wishing   never born       thought  emotion    really care  anything  many   thought   wishing  could disappear  wishing   le  every possible way  want    alive     feel  emotion  feel    often contemplate different way  kill    moreso  wishing    born   first place  hoping someday something else  happen    make  decision    majority   thought  wishing   dead  never born  even    happy   wish  could stop feeling   answer      death   way   feeling considered suicidal thank   reading  comment   appreciated  answered</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>crave  eternal silence  slumber  come   6 foot deep grave tonight   great night  contemplate whether     attempt  end  life   indubitably    worth anything    contrary   belief   redditors   reply     never  done anything correct   life    ever succeeded      hurtful  disrespectful  others  taking others  granted   breed  catastrophe      talented  skilled  anything  particular    average  every concept known  man    motivation  intention  progress   life  seem    inconvenience  unpleasant burden towards society   say  existence    comparable   tumor    productive   produce negative effect  others  unfortunately   unbearable pain  come  interaction  someone like  entrapped   body  dream  going  eternal sleep  great rest  last   end  time      interest  anything anymore daily politics bore   great deal       intrigued  life      see  reason   follow        intrinsic value   drive  intent  live</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>want  feel like thisi went  casually  someone  died  suicide week   found    seeing  people   even called thing    back   didnt think  would  wrong   thought  made  really clear    liked     exclusive sometimes  self blame  guilt get  immense  overwhelming   want  go  sometimes   terrified     really  fault  would come bite    as one day  thought intensifies  urge  tap    think  would take  blame    also scare  whenever  remember  analogy  glass  full        glass spill     empty  glass    fault   ever feel like      okay  feel like</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>planned  dying today obviously    dead instead   fucking drunk like  useless little shit</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>ptsd attack</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>bad   like drawing picture   brain  surgically removed   crushed   steamroller  ton  blood    chronic neurological illness see post history  entire account  mine  venting   illness thats  destroying  fucking life     lot  make 3d art   made 3d animation  brain  tortured  imagining    brain like  brain  torn apart cut open   chainsaw etc</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>actually depressed     diagnosed  depression     bring   courage  tell anyone    feeling   researched     symptom   constant suicidal thought     sh problem  everyday  keep feeling worse  feel utterly worthless  stupid     know     really hard  type  post    never opened   much  anybody   felt  way   long time like   year   really want  know   wrong    almost never enjoy  life anymore   want  give     scared  hurting family member  always act  happy  cheerful around      want   find   truth  someone give   answer</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>sure  else  turni  nothing  negative thought   time   remember   started    gotten  bad  tend  cry   sleep   even  sleep    know   talk     really  anyone  talk     want  dump everything   maybe get  guidance    something  make  pain go away  never see  parent due   mom  step dad   busy  work  running  business   dad  probably somewhere rotting  arizona  sister  deployed   navy    ran away   year ago    heard     older brother   drug addict  cut tie  u  long time ago    want  message  suicide hotline   fear   send  ambulance  force    hospital forcing bill       afford     one close  talk     situation  growing   parent  lived  different bad area  little money   never smart  talented  anything besides    active imagination  always   learning issue   paying attention  remembering information regardless   hard  tried     lot  friend  ended  dropping   high school  3 year ago  went back  got  adult diploma   hope  would  enough  get    foot    almost 26     month ago   saw someone ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>life  literally getting darker every dayi dont know     right sub   need  place  vent right    dont know   start    depressed   6 year   always managed  see  good thing  life    last 2 month  got worse  randomly   urge   cry  day long     holding  back  probably     good idea also  still live   mom  every time  get home   yell     last 3 week  got really tired  soon   get home   lay   bed  try  relax  even  vision  getting darker  think  dont know   going      dont think   keep going much longer</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>subreddit  kinda therapeutic    personal experience  seeing  people go    struggle  go   kinda calming   people  obviously going  thing much worse also people    much  sympathetic  kind   wonderful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>life  overratednow    right   complaining   asian family   get strict     pressure   smart  peer  even teacher  since    fragile hoe   depressed   want  life  end    huge hypocrite   get mad    ordinary thing    important one example   ridiculous hypocrisy    ranted   friend     terrible family situation  constantly insulted   said    faking depression  begging  attention      begging  sympathy     right   saying anything  people   depressed   inclined  act  way  even   make fun      know   wrong   except  everything      one begging  sympathy    somewhat glad  nobody give        deserve sympathy  feel    really ironic    talking      made  project convincing people   commit suicide oh      recommend slitting  jumping  could write sooo much     kinda lazy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>really need help guy m13my parent got  divorce like  june  whole life turned upside   got depression  grade  failing     suicidal recently   found    dad   cheating   mom    year   divorce  really messed     want someone  talk  please pm  want  talk      normal conversation please someone</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>want    stopeveryone end  hating  eventually  psychologist  almost ten year blew     kicked     last session   doubting every interaction    every person  meet   doubting every interaction    every single one   friend    get  substance abuse issue  control     worst enemy   accused    bully   subsequently bullied   workplace bullying system  uprooted  life  change   better   part   domino     dog  killed  would give anything    different person right        awful repulsive contemptible self</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    post_lem  \\\n",
       "919                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       everyone   backstabbing sack  shit   \n",
       "942                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                depression  got worse   lost  cati  got better  little bit    drinking  cry nonstop     beside cutting   drinking alcohol   \n",
       "290  anyone  wanna talk     sorry   error english   first language     anxious right     long story    kind  confusing    go   depressed since ever    know   started    started   thing   know     depressed since    kid  thing  getting worse  worse    big crisis   last two year life      expecting    thing   complicated  tried tried    still  fucked  thing   cousin life  another country   asked    could stay    3 month  thing get better    organize   live    moved  one month ago    trying  build thing  live  maybe another country another life maybe thing get better    know   trying   asked     stay   home   really kind  supportive    august 2019   got  last month     nice    wake    purpose  say bad thing like   watch  tv cause   sleeping   couch  couch   bed   insinuated    find  place   since  day  arrived   try    help  thing  clean  house  wash  clothes  go  supermarket  buy  food  cook  food  try   outside     give   space  still   acting bad towards     know    since  asked      3 ...   \n",
       "445                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          well  see   fun   worldnothing aint fun nomore nothing excites  nomore nothing  look foward  nomore life aint fun nomore  whats  point  staying   \n",
       "167                                                                                                                                                                                                                                                                                                                                                                   find  sense  power  anything   hitting     situation  fucked every one    fucked  hate  fact    headed  nothing   meaningless middle class civilian life   influence  meaning  anyone  get  fucking angry  everything happening   world around      want   forced  play  rigged game   time  feel much authority  anything    body smacking   hard   possibly        suffering like  since   born      long like    want  cry   help         honest   people  know  even    cry   one would listen  like       cry  screaming  loud      pillow   last ten minute    cry screaming animal trapped   cage    processed  meat meat    even  enjoyed  anyone  thrown away   \n",
       "222                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         old brain  common     life   planet     addition  new   hate     reason   problem fuck new brain   \n",
       "377                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    bullshitso  went   stupid therapist last week    self harm  suicide thing   school  dont really want help     least hoping   help   mental health  didnt happen instead   going  get tested  autism asperger   dont think   autism  bad     really   wanted  wanted  sort   mental health      take    thing  could mean   autistic   hate   dont get    referred   therapist  specializes  autism      need sorry    offensive sorry   \n",
       "827                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       feeling suicidali   hospitalised twice  last  week  severe depression suicidal thought  anxiety  fianc    broken       absolute mess     one  someone please tell     ok   broken   \n",
       "296                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               tired  people saying   get better    constantly  getting worsefucking liar   \n",
       "778     know   talk  anymore    around 6 7    dad got  scholarship  australia   really happy      someone   lot  friend exceptional grade etc   turned 180   came back  australia   home country     know  junior high  pretty average execpt  grade  starting  fall   got  occasional teasing     different english accent  come high school  everything hit real hard  grade   par  dad   allow   hang   friend  started   heli parent  would make irrational night curfew  also got  numerous trouble  school  time   thought   friend left  one  one  even spread  rumor    gay  big    country   top    girlfriend cheated    felt  desolate  unwanted ever since   became socially awkward   started  stutter mumble   speech  thought  jumping   roof  canceled eventually   ate  depression  loneliness     time gaining 10 kilo   making  obese last year  got accepted  uni   city away  home  gave   much needed liberty away   dad  tried making friend   usual stuff   shrugged    cool enough     plain awkward person  kil...   \n",
       "820                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     w  fun ride   lasted   \n",
       "740                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           turn 32  april  job  friend  girlfriend  life   title say     degree     confidence  suffer  social anxiety    little work experience  lost   friend year ago  romantic interest     leave  house except   morning run  feel totally lost    idea      parent  worried   let    keep asking    plan      answer    want  see  family   birthday   embarassed   something fundamentally wrong     depression maybe     trance   keep repeating   thing day  day   idea   change   \n",
       "288                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ehi  usually ok   still hate   often fantasize  death  detailed way anyone else   \n",
       "968                                                                                                                                                                                                                                                                                                                                                                                                                                       nothingi  lost  fight   nothing   point  ball  emotion barely fucking human   lost  motivation  go     even pushing back   destruction  brain wreck    special unique important smart helpful  human   sense    selfish lying bastard piece  shit   insignificant  background man          fake  fake built   conceal  blackness  horrible person  really      happy ever  everything  put     mask  hide  nothingness nobody need       life  take   point   numb     feel  anymore   tired  waiting fighting disguising  trying   losing    nothing     win    end  doubt  find solace  anything   \n",
       "512                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         suicidewhen   turn 18  want  kill   feel like     waste  space   friend  staying     pity  every time   think    see  failure   never  able   anything good    asking  advice        lost   mind   \n",
       "291   want  die    actually uselessi got  talent whatsoever  got nothing  want    tried hard  search          good    find    actually hopeless     fucking talent whatsoever  motivation  anything  well    huge disappointment  everyone around    hurt  love  friend  family  want    proud      nothing     proud   recently   tried  best  everything studying socializing class   taking everything    motivation  making  parent  friend proud    useful human     love      loveable  lost  motivation recently   parent said     good enough said  younger sister  better    laughed  got pissed  told    trying  best   told         result grade   evidence  got 2 b   math  social study  0 1  0 2 difference  otherwise    called  dumb    regret spending  much money      going    way  working hard   getting  best result  said    acting depressed   reason    whining   life    spoiled  break  completely  father said   losing motivation  go  work  earn money    wasting    mother said  disappoint     fault     ...   \n",
       "571                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              think   woke  one day happy   longer suicidal   probably die   massive heart attack   shock 48m   dealt  depression  suicidal thought  probably 35 year      pretty much   different med  2 round  tm 30 session     therapy nothing  made  feel  better    remember   way  feel  sad hopeless  suicidal    know  much longer   keep going    \n",
       "228                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          someone talk   please   feeling sick anxious  need  help please   \n",
       "799                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                would  friend care   died  closest friend   distant lately mostly busy   job  friend  partner  feel    really care      hard  get  contact    gave    depression would  even care    dead   \n",
       "776                                               give  one reason  carry    life     missing   almost every joy imaginable  never   best friend   never  part   friend group   group   matter  never felt accepted    temporary job   waiter   online chat    class never   girlfriend never kissed never  sex never  someone compliment  never   unforgettable holiday trip never   memorable spring break  summer break never went   cool festival never   great party never hosted one either  list go       feel lonely   depression  physically weighing       motivation   anything     parent say   read    face  legit cannot remember  last time   fun  would  even bother going  like    feel like    surviving  day rather  living   almost tempted  move  another country start anew   go entirely crazy   feel like  would carry    way   even  depressed everyone around    much fun   last week  overheard two normal guy around  age discussing  plan   summer   crazy memory  wanted  kill   badly hearing   missed   fuck   \n",
       "253                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 help mei   felling kind  sad lately     sure   sub   right one   help   sorry   english  dumb    make  mistake  friend secretly wanted   leave  alone    say  without   hard enough  life   kinda falling apart   need  advice  keep  going  please help   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              anyone angry  bitter   time    tolerate anybody  hate  sound   voice child playing car people laughing anything   always sort   loner      tolerate  human presence   point  friend   character  create  people  want  talk      life    fine   nobody   life understands   even care enough  try  understand   \n",
       "10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              guy replay  life   head     replaying  entire life   head recently    thinking  lot   childhood       child   experience   mostly positive  feel like  could snap   day   okay       help  think  memory   completely unrelated   depression   \n",
       "913    visit  psychiatrist  16 currently going  depression    talk  anyone    visiting  psychotherapist   2 year   psychiatrist  several week   decided  stop going  like 6 month ago    diagnosed  social anxiety   depression  never actually talked    anyone  even   parent   therapist  everyday life go like  wake  survive 7 hour  school come home play video game  rest   day since     anything better   cry  sleep repeat  school  barely speak  anyone even though   going    class   5 year    1 2 friend   mostly  see    last choice everytime   want  meet    one else  time recently  got someone new   class   seems like    social contact   everyone else   past 3 day     last 5 year everyone think    introverted    kinda true     get rejected  everyone  even try  talk   get excluded  everything  people throw party  never get invited  people  barely talk  get invited  grade  horrible      get   school    even know   want  become since   stopped caring   noticed  everyone ignores    matter  hard  ...   \n",
       "276  life suck   think   something wrong   ever since  came   state  college       depressive state  mind school killed  passion    wanted     shit ton  work  almost  free time    want  change school take  gap year    unable    due  financial reason     friend  school   classmate   feel  like coworkers    concerned      career   friend  family   feel like  family    nightmare  everyone hate    used     optimistic guy   little pessimism    feel like  pessimistic side  taken    think     inner voice  tell     go ahead  kill      easy solution  every single problem    also noticed       original self anymore  lose patience way faster   used   get upset  easily   much   feel like   lost   self    know    anymore everything seems pointless  nothing motivates   work hard  live life anymore   know    act  suicide  understand    wrong  selfish   reason  suicide   reasonable    keep telling        rough patch  life      small hill      climb  school    hand    lot  work  stress piled    amount  ...   \n",
       "878                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  2 month left           meantime  thought  planting flower  hanging   friend also  try  make  comic btw   suggest getting help  already go   therapist  take ad     handle  life anymore school    hard    constantly feel tired  mark got worse  lost  motivation  keep going    reason     feel like sharing  know maybe   couple  month   feel better thanks  advance   \n",
       "900                                                                                                                                                                                                               wrong   brain  life  okay pretty good  guess wish  made  money    happy       matter  still feel    strong need  kill    last    like  week    short term like   hour sometimes  feel like    slit  wrist   tub  put  bullet   brain  swerve   truck   know better   something   brain   triggering     christian  real one   ask god  time  take      help    like  voice  little guy   shoulder waiting  watching  anything  trigger  uhg  frustrating  think    dog  husband  brother sister  niece  nephew need    voice   care    wondering     part   brain      never done hard core drug   mother  high  speed    pregnant       dopamine issue     drug  fall  deep depression  get suicidal   maybe   hereditary  maybe    drug    pregnant caused  issue   brain anyway  thought would  helpful thank   advance   \n",
       "634  stress  loneliness  dragging   againafter 29 year    shut  sometimes  social anxiety  bad     step   house  go near  window mental health  bad     work  finish school  decided  go back  school   dependent   longtime    make  feel awful    element  abuse   past   dont think   fully trust anyone        die  get  high paying job without  degree  hurting  back    terrible back  neurological problem    left  something like stripping   suicide amp nbsp   point class  getting  intense   already behind   online class  posted  deadline    prioritizing  class    work around 30 hour week  keep  quality high   aiming      class  supposedly graded harshly  far      1 b  something  worked    10 hour anyway    behind   online class  trying  make time  catch   seems impossible amp nbsp    person class   take  much time    4 hour studio  homework take  maybe 1 5 hour usually   trouble managing time   hardly see       see    stay  late   play game  havent   intimacy    month  otherwise   like  1 2x ...   \n",
       "436                                                                                                                                                                                                                                                                                                     thought  getting back   mindi     told everyone   run away  never come back take   life  f everything life got better   short        take long    lose everything  seemed worth   back  got divorced thrown   flat  whole lot  lawyer bullshit   lot  negative thought basically    truly happy since    thing  turning  shit    feeling   suicidal thought  slowly finding  way back      med  seeking professional help   still feel  lost    time feel like   failing  every little thing   turning away  people  adore    fair   often feel like    torn apart form  inside     surely getting sick      depressed   long    think   sure    hold  together  much longer feel like  rant perhaps   help thank    attention  time   \n",
       "105                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        im  longer clean   feel  much betteri hate  pain  cuttinf    havent    year   felt  slipping   paranoia attack   really wanted  sleep tonight       \n",
       "39    f24   traumatic experience   ruining  life   lost hope  living please read throwawayacc   extremely depressed  feel like  life  ended  incident  happened  affected  life extremely negatively  lost   friend    longer talk  anyone  go    scared  tell anyone  happened       embarrassed  live       support  anyone  partner  tired   dealing   depression  seems never ending  feel like   ready   end   really    anyone  talk   stay   bed   time   literally ignoring everyone  starve   day sometimes    stay   bed   never ever ever dealt  anything like    life  feel like   lost everything       concerned   loss   baby read story  understand  anything    honestly  denial    happen  feel like    even want  accept    pregnant   living  denial  really need someone  talk    sr think   ready  end  please  would help  someone listened    know  story   bit long   would really appreciate  anyone could  listen   least reply  something kind anything really  apologize  typo  bad grammar    throw away ac...   \n",
       "281                                                                                                                                                                                                                                                                                                                                                                             tired  acting happy   tired   alivemy whole life   lie   act happy    people expect      fuck could   happy    18     several people u know kill    watched   man drown  death right  front     parent make  go right back   spot   happened right   grandma  house    sleep twenty foot away      told  man   deal   well   fucking tired  pretending    molested   father left     twice    happy    piss     sense  left     awnser  call   never get  see  little sister two      never get  meet   know    good boy   need  smile   pain    happy right     family say      society say        woman      sexual attacked     depressed   sad   fuck      \n",
       "171                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ppl say u need help   really mean    fucking problem  feel like  could go week without  contact  ppl   forget  dont know         machine mind   machine world let  go   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   could use someone  talk    \n",
       "974                                                                                                                                                                suicidal hi    sure    one   thing      ask      definite answer     sure    experience  truly suicidal thought     feel sad  become  thankful    try  express  god thanks     given   feel guilty  spending  time self harming   self destructive  feel   never  able  truly convey  thankful       given     back  square one  wishing   never born       thought  emotion    really care  anything  many   thought   wishing  could disappear  wishing   le  every possible way  want    alive     feel  emotion  feel    often contemplate different way  kill    moreso  wishing    born   first place  hoping someday something else  happen    make  decision    majority   thought  wishing   dead  never born  even    happy   wish  could stop feeling   answer      death   way   feeling considered suicidal thank   reading  comment   appreciated  answered   \n",
       "558                                                                                              crave  eternal silence  slumber  come   6 foot deep grave tonight   great night  contemplate whether     attempt  end  life   indubitably    worth anything    contrary   belief   redditors   reply     never  done anything correct   life    ever succeeded      hurtful  disrespectful  others  taking others  granted   breed  catastrophe      talented  skilled  anything  particular    average  every concept known  man    motivation  intention  progress   life  seem    inconvenience  unpleasant burden towards society   say  existence    comparable   tumor    productive   produce negative effect  others  unfortunately   unbearable pain  come  interaction  someone like  entrapped   body  dream  going  eternal sleep  great rest  last   end  time      interest  anything anymore daily politics bore   great deal       intrigued  life      see  reason   follow        intrinsic value   drive  intent  live     \n",
       "319                                                                                                                                                                                                                                                                                                                                                                                                                                                                            want  feel like thisi went  casually  someone  died  suicide week   found    seeing  people   even called thing    back   didnt think  would  wrong   thought  made  really clear    liked     exclusive sometimes  self blame  guilt get  immense  overwhelming   want  go  sometimes   terrified     really  fault  would come bite    as one day  thought intensifies  urge  tap    think  would take  blame    also scare  whenever  remember  analogy  glass  full        glass spill     empty  glass    fault   ever feel like      okay  feel like      \n",
       "158                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               planned  dying today obviously    dead instead   fucking drunk like  useless little shit     \n",
       "684                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ptsd attack   \n",
       "117                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       bad   like drawing picture   brain  surgically removed   crushed   steamroller  ton  blood    chronic neurological illness see post history  entire account  mine  venting   illness thats  destroying  fucking life     lot  make 3d art   made 3d animation  brain  tortured  imagining    brain like  brain  torn apart cut open   chainsaw etc   \n",
       "612                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   actually depressed     diagnosed  depression     bring   courage  tell anyone    feeling   researched     symptom   constant suicidal thought     sh problem  everyday  keep feeling worse  feel utterly worthless  stupid     know     really hard  type  post    never opened   much  anybody   felt  way   long time like   year   really want  know   wrong    almost never enjoy  life anymore   want  give     scared  hurting family member  always act  happy  cheerful around      want   find   truth  someone give   answer   \n",
       "672     sure  else  turni  nothing  negative thought   time   remember   started    gotten  bad  tend  cry   sleep   even  sleep    know   talk     really  anyone  talk     want  dump everything   maybe get  guidance    something  make  pain go away  never see  parent due   mom  step dad   busy  work  running  business   dad  probably somewhere rotting  arizona  sister  deployed   navy    ran away   year ago    heard     older brother   drug addict  cut tie  u  long time ago    want  message  suicide hotline   fear   send  ambulance  force    hospital forcing bill       afford     one close  talk     situation  growing   parent  lived  different bad area  little money   never smart  talented  anything besides    active imagination  always   learning issue   paying attention  remembering information regardless   hard  tried     lot  friend  ended  dropping   high school  3 year ago  went back  got  adult diploma   hope  would  enough  get    foot    almost 26     month ago   saw someone ...   \n",
       "664                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     life  literally getting darker every dayi dont know     right sub   need  place  vent right    dont know   start    depressed   6 year   always managed  see  good thing  life    last 2 month  got worse  randomly   urge   cry  day long     holding  back  probably     good idea also  still live   mom  every time  get home   yell     last 3 week  got really tired  soon   get home   lay   bed  try  relax  even  vision  getting darker  think  dont know   going      dont think   keep going much longer   \n",
       "714                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    subreddit  kinda therapeutic    personal experience  seeing  people go    struggle  go   kinda calming   people  obviously going  thing much worse also people    much  sympathetic  kind   wonderful   \n",
       "421                                                                                                                                                                                                                                            life  overratednow    right   complaining   asian family   get strict     pressure   smart  peer  even teacher  since    fragile hoe   depressed   want  life  end    huge hypocrite   get mad    ordinary thing    important one example   ridiculous hypocrisy    ranted   friend     terrible family situation  constantly insulted   said    faking depression  begging  attention      begging  sympathy     right   saying anything  people   depressed   inclined  act  way  even   make fun      know   wrong   except  everything      one begging  sympathy    somewhat glad  nobody give        deserve sympathy  feel    really ironic    talking      made  project convincing people   commit suicide oh      recommend slitting  jumping  could write sooo much     kinda lazy   \n",
       "410                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        really need help guy m13my parent got  divorce like  june  whole life turned upside   got depression  grade  failing     suicidal recently   found    dad   cheating   mom    year   divorce  really messed     want someone  talk  please pm  want  talk      normal conversation please someone   \n",
       "14                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           want    stopeveryone end  hating  eventually  psychologist  almost ten year blew     kicked     last session   doubting every interaction    every person  meet   doubting every interaction    every single one   friend    get  substance abuse issue  control     worst enemy   accused    bully   subsequently bullied   workplace bullying system  uprooted  life  change   better   part   domino     dog  killed  would give anything    different person right        awful repulsive contemptible self   \n",
       "\n",
       "     suicide  predictions  \n",
       "919        1            0  \n",
       "942        1            0  \n",
       "290        1            0  \n",
       "445        1            0  \n",
       "167        1            0  \n",
       "222        1            0  \n",
       "377        1            0  \n",
       "827        1            0  \n",
       "296        1            0  \n",
       "778        1            0  \n",
       "820        1            0  \n",
       "740        1            0  \n",
       "288        1            0  \n",
       "968        1            0  \n",
       "512        1            0  \n",
       "291        1            0  \n",
       "571        1            0  \n",
       "228        1            0  \n",
       "799        1            0  \n",
       "776        1            0  \n",
       "253        1            0  \n",
       "3          1            0  \n",
       "10         1            0  \n",
       "913        1            0  \n",
       "276        1            0  \n",
       "878        1            0  \n",
       "900        1            0  \n",
       "634        1            0  \n",
       "436        1            0  \n",
       "105        1            0  \n",
       "39         1            0  \n",
       "281        1            0  \n",
       "171        1            0  \n",
       "4          1            0  \n",
       "974        1            0  \n",
       "558        1            0  \n",
       "319        1            0  \n",
       "158        1            0  \n",
       "684        1            0  \n",
       "117        1            0  \n",
       "612        1            0  \n",
       "672        1            0  \n",
       "664        1            0  \n",
       "714        1            0  \n",
       "421        1            0  \n",
       "410        1            0  \n",
       "14         1            0  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 1000)\n",
    "fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After studying the posts, there seems to be no clear trend. That said, there are some that could have just posted in the subreddit while showing mild symptoms of depression, rather than being in a more 'advanced' stage of depression that could potentially be a suicide case. Besides, different people express themselves differently and what could have been a genuine cry for help such as 'could use someone to talk to' might not have been phrased the same way by others having the same suicidal thoughts. There is definitely a need for more data for the model to be able to pick up the minor differences in how people express themselves. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Production Model**\n",
    "\n",
    "As mentioned above, the production model would be **Tfidf Vectorization with Multinomial Naive Bayes**, which gave a rather high recall rate of 81% - the fraction of the total amount of suicidal instances that were actually retrieved by the model. \n",
    "\n",
    "**Limitations**\n",
    "\n",
    "It is important to recognise the limitations of using posts or written notes of any kind to raise red flags about potential suicide cases. The written notes cannot capture the tone in which it is written and cannot capture a person's behavioural changes which usually serves as a telltale sign. Thus, while it can be useful as a form of first screening, there is also a need to examine behavioural changes in relationships, eating and sleeping habits, etc.\n",
    "\n",
    "**Further Expansion**\n",
    "\n",
    "The two subreddits used are depression and suicide, which means that it could fail to classify those who are suicidal and at the same time, face depression correctly. The project could benefit from widening the scope of data collection to include people who may be suicidal due to other conditions like trauma and anxiety. \n",
    "\n",
    "Besides, higher data granularity, such as location, age, and gender would probably help in classifying because people from different regions, genders and age would express themselves differently. This will help identify the nuances and classify the categories better. The project can also be generalised to include more stakeholders such as parents, the community and teachers to help identify suicidal patients early on. It will be particularly helpful for those who do not have background in the field, i.e. those who are not trained psychologists and psychiatrists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
